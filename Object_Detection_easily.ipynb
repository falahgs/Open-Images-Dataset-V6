{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object Detection easily",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOlrUQM6JSpN9VfqmF45rRM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/falahgs/Open-Images-Dataset-V6/blob/master/Object_Detection_easily.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wW6djgVt7Lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1na6A9e__vz",
        "colab_type": "text"
      },
      "source": [
        "**Train your own Object Detection easily**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV8D7Ovst86v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://medium.com/@jonykoren/train-your-own-object-detection-easily-97e7f4168c26"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKd8Kz0XyQVj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5e926016-2454-48b1-c944-b6dee26b3b6c"
      },
      "source": [
        "!git clone https://github.com/jonykoren/Object_Detection_YOLOv3.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Object_Detection_YOLOv3'...\n",
            "remote: Enumerating objects: 227, done.\u001b[K\n",
            "remote: Counting objects: 100% (227/227), done.\u001b[K\n",
            "remote: Compressing objects: 100% (218/218), done.\u001b[K\n",
            "remote: Total 227 (delta 118), reused 27 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (227/227), 17.17 MiB | 24.15 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q6koIF1yUNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95ab2c86-a86a-4efe-b62e-4faee5f6760f"
      },
      "source": [
        "cd /content/Object_Detection_YOLOv3/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Object_Detection_YOLOv3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz-HQMrezEQV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3af8b656-aa24-44ba-8d30-107e577e0b8b"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "config\t\t     evaluate_mAP.py\t    modules\t     requirements.txt\n",
            "detect.py\t     Generate_xml_files.py  Prepare_data.py  train.py\n",
            "download_dataset.py  model_data\t\t    README.md\t     yolov3.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlSVTspFzUfu",
        "colab_type": "text"
      },
      "source": [
        "** **bold text**Download Dataset**\n",
        "\n",
        "I choose to download subset from ‘Open Images Dataset V6 + Extensions’, by selecting specific classes that i want to train my model on.\n",
        "The classes parameter determines which classes you want to download, and limit parameter determines how many pictures you want to download\n",
        "You can leave this command lines as is but if you want to change the classes, you can explore your own classes at the: \n",
        "\n",
        "Open Images Dataset.\n",
        "\n",
        "https://storage.googleapis.com/openimages/web/index.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjeZ06To2WhX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c0be4777-7208-4185-c88d-034354b5150b"
      },
      "source": [
        "!git clone https://github.com/EscVM/OIDv4_ToolKit.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'OIDv4_ToolKit'...\n",
            "remote: Enumerating objects: 422, done.\u001b[K\n",
            "remote: Total 422 (delta 0), reused 0 (delta 0), pack-reused 422\u001b[K\n",
            "Receiving objects: 100% (422/422), 34.08 MiB | 41.01 MiB/s, done.\n",
            "Resolving deltas: 100% (146/146), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iACLOLQ2nJD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "d263d46e-204e-4d86-cca0-78bf49320ed9"
      },
      "source": [
        "!pip3 install -r /content/Object_Detection_YOLOv3/OIDv4_ToolKit/requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r /content/Object_Detection_YOLOv3/OIDv4_ToolKit/requirements.txt (line 1)) (1.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r /content/Object_Detection_YOLOv3/OIDv4_ToolKit/requirements.txt (line 2)) (1.18.5)\n",
            "Collecting awscli\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/47/49f27480e66392dd1d59b68cc3c4385b6d9e8ac10f3c09e913cc3a87f442/awscli-1.18.137-py2.py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from -r /content/Object_Detection_YOLOv3/OIDv4_ToolKit/requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r /content/Object_Detection_YOLOv3/OIDv4_ToolKit/requirements.txt (line 7)) (4.41.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from -r /content/Object_Detection_YOLOv3/OIDv4_ToolKit/requirements.txt (line 9)) (4.1.2.30)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r /content/Object_Detection_YOLOv3/OIDv4_ToolKit/requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->-r /content/Object_Detection_YOLOv3/OIDv4_ToolKit/requirements.txt (line 1)) (2.8.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from awscli->-r /content/Object_Detection_YOLOv3/OIDv4_ToolKit/requirements.txt (line 3)) (0.3.3)\n",
            "Requirement already satisfied: PyYAML<5.4,>=3.10; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from awscli->-r /content/Object_Detection_YOLOv3/OIDv4_ToolKit/requirements.txt (line 3)) (3.13)\n",
            "Collecting colorama<0.4.4,>=0.2.5; python_version != \"3.4\"\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from awscli->-r /content/Object_Detection_YOLOv3/OIDv4_ToolKit/requirements.txt (line 3)) (0.15.2)\n",
            "Collecting botocore==1.17.60\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/68/ed0b1d62bf7621a3cc4ff3ad4d55552250fc859da9efff56cf82e9dc2672/botocore-1.17.60-py2.py3-none-any.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 41.8MB/s \n",
            "\u001b[?25hCollecting rsa<=4.5.0,>=3.1.2; python_version != \"3.4\"\n",
            "  Downloading https://files.pythonhosted.org/packages/26/f8/8127fdda0294f044121d20aac7785feb810e159098447967a6103dedfb96/rsa-4.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->-r /content/Object_Detection_YOLOv3/OIDv4_ToolKit/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from botocore==1.17.60->awscli->-r /content/Object_Detection_YOLOv3/OIDv4_ToolKit/requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=4.5.0,>=3.1.2; python_version != \"3.4\"->awscli->-r /content/Object_Detection_YOLOv3/OIDv4_ToolKit/requirements.txt (line 3)) (0.4.8)\n",
            "Installing collected packages: colorama, botocore, rsa, awscli\n",
            "  Found existing installation: botocore 1.17.48\n",
            "    Uninstalling botocore-1.17.48:\n",
            "      Successfully uninstalled botocore-1.17.48\n",
            "  Found existing installation: rsa 4.6\n",
            "    Uninstalling rsa-4.6:\n",
            "      Successfully uninstalled rsa-4.6\n",
            "Successfully installed awscli-1.18.137 botocore-1.17.60 colorama-0.4.3 rsa-4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54iQeijR2vtr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "c5d64aaa-a5d6-431c-f209-1fcdc829bc07"
      },
      "source": [
        "!python /content/Object_Detection_YOLOv3/download_dataset.py downloader --classes Man Woman --type_csv train --limit 100\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Man.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the class-descriptions-boxable.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...145%, 0 MB, 57014 KB/s, 0 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File class-descriptions-boxable.csv downloaded into data/csv_folder/class-descriptions-boxable.csv.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the train-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...100%, 1138 MB, 41307 KB/s, 28 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File train-annotations-bbox.csv downloaded into data/csv_folder/train-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mMan\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 378077 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 100 images.\u001b[0m\n",
            "    [INFO] | Download of 100 images in train.\u001b[0m\n",
            "100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Man of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Woman.\u001b[0m\n",
            "\n",
            "\u001b[95mWoman\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 265635 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 100 images.\u001b[0m\n",
            "    [INFO] | Download of 100 images in train.\u001b[0m\n",
            "100% 100/100 [00:55<00:00,  1.80it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Woman of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgrRQzw13IFn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "13eb2a38-c3a7-4be4-ab76-6199810acd22"
      },
      "source": [
        "!python /content/Object_Detection_YOLOv3/download_dataset.py downloader --classes Man Woman --type_csv test --limit 10\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Man.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the test-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...100%, 49 MB, 49102 KB/s, 1 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File test-annotations-bbox.csv downloaded into data/csv_folder/test-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mMan\u001b[0m\n",
            "    [INFO] | Downloading test images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 8412 online images for test.\u001b[0m\n",
            "    [INFO] | Limiting to 10 images.\u001b[0m\n",
            "    [INFO] | Download of 10 images in test.\u001b[0m\n",
            "100% 10/10 [00:09<00:00,  1.00it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Man of test.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Woman.\u001b[0m\n",
            "\n",
            "\u001b[95mWoman\u001b[0m\n",
            "    [INFO] | Downloading test images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 5859 online images for test.\u001b[0m\n",
            "    [INFO] | Limiting to 10 images.\u001b[0m\n",
            "    [INFO] | Download of 10 images in test.\u001b[0m\n",
            "100% 10/10 [00:09<00:00,  1.00it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Woman of test.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjemQ_Lr3_Nq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d96a3356-7920-4210-b186-8e259a544186"
      },
      "source": [
        "!python /content/Object_Detection_YOLOv3/Generate_xml_files.py\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Currently in Subdirectory: train\n",
            "\n",
            "Creating PASCAL VOC XML Files for Class: Man\n",
            "100% 100/100 [00:01<00:00, 73.56it/s]\n",
            "\n",
            "Creating PASCAL VOC XML Files for Class: Woman\n",
            "100% 100/100 [00:01<00:00, 78.40it/s]\n",
            "Currently in Subdirectory: test\n",
            "\n",
            "Creating PASCAL VOC XML Files for Class: Man\n",
            "100% 10/10 [00:00<00:00, 78.44it/s]\n",
            "\n",
            "Creating PASCAL VOC XML Files for Class: Woman\n",
            "100% 10/10 [00:00<00:00, 86.70it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g25a3ZOULD8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir config_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWp5E4xm4fUh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34ff095c-2b7c-4c9c-aa88-6aaa61756bb3"
      },
      "source": [
        "!python /content/Object_Detection_YOLOv3/Prepare_data.py\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Object_Detection_YOLOv3/data/Dataset/train/\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/4e12be8dfad96dd9.jpg 324,131,634,565,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/b90053bcbeb9f59a.jpg 98,59,670,938,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/5a3cd576da7e5e6e.jpg 751,259,1024,664,0 0,158,281,663,0 536,340,876,663,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/bf9f7c83fb9af940.jpg 0,228,239,568,0 105,194,266,481,0 358,174,723,682,0 579,287,812,682,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/fc91fa8422713319.jpg 85,122,243,611,0 225,103,365,595,0 341,104,483,589,0 451,129,607,592,0 556,119,705,573,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/fffb87e0e14832d8.jpg 634,292,780,741,0 168,281,293,767,0 223,313,408,767,0 363,309,493,711,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/99ee7736a3d9272d.jpg 766,14,1012,670,0 2,73,315,891,0 44,137,128,242,0 242,249,330,386,0 297,72,727,739,0 318,27,587,511,0 541,80,797,594,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/7ea8a37ba46f2041.jpg 14,119,237,753,0 237,178,444,752,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/88ff719a6c5da04c.jpg 346,522,504,665,0 355,430,392,508,0 459,458,568,569,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/68b11e638885a979.jpg 73,33,713,1023,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/97a05bd5e76bf180.jpg 564,259,780,664,0 28,265,125,616,0 79,228,404,682,0 291,220,329,308,0 419,275,467,374,0 425,229,585,682,0 535,278,564,339,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/18eb664fa6e7f718.jpg 739,512,976,754,0 0,399,1023,767,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/5eec044a8535a9cf.jpg 134,104,746,945,0 683,256,709,289,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/ca9db18bc699f777.jpg 547,12,1018,596,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/7067f3144e69034b.jpg 0,107,398,1023,0 349,145,643,947,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/ab47f23fc4e4af2e.jpg 29,34,683,929,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/90dfc72095f9915f.jpg 502,250,595,501,0 120,277,147,324,0 164,284,218,474,0 392,236,449,430,0 740,224,849,544,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/f69d706b79343923.jpg 120,237,319,861,0 0,16,105,903,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/a2b336e494e6bcf6.jpg 102,53,445,521,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/ceccfc3274749868.jpg 520,345,587,463,0 835,332,920,543,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/32fbadc9bed6c46f.jpg 145,399,183,493,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/09921beee0300a8b.jpg 499,144,989,668,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/ffc2ca238f59306d.jpg 0,35,294,552,0 168,109,471,471,0 383,69,980,682,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/26667d54b4f076b1.jpg 54,574,122,754,0 140,590,206,768,0 302,557,327,630,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/71a1c54c96c7daff.jpg 17,296,90,527,0 308,241,428,682,0 504,465,818,682,0 538,215,652,498,0 833,505,1023,682,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/e6a53e94a4a82ba2.jpg 423,177,502,337,0 562,215,698,574,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/e608acead9a83879.jpg 661,49,906,559,0 213,102,287,188,0 316,80,431,361,0 582,71,681,200,0 667,100,757,189,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/59ca568e542d39ae.jpg 0,0,253,934,0 0,325,641,731,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/b65bd1966bce2cdf.jpg 205,298,434,877,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/86c0e055bf905c3e.jpg 10,75,336,682,0 211,133,549,680,0 544,243,795,680,0 658,0,1022,680,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/5c4218961f2265ee.jpg 90,161,744,871,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/bcd639509850fe04.jpg 268,161,740,836,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/f14b63f48b4ca744.jpg 568,26,940,768,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/ba7b86410d14b8bc.jpg 303,241,394,589,0 387,209,485,614,0 551,273,644,567,0 652,225,781,621,0 779,230,897,712,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/f7e5730a3c908db8.jpg 29,175,180,622,0 152,205,266,602,0 553,221,661,593,0 644,246,708,563,0 676,223,740,551,0 689,235,799,589,0 771,222,892,571,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/f99e8b2bab8c9dbf.jpg 410,281,690,671,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/07eefbaf03514870.jpg 43,275,63,356,0 191,275,220,343,0 333,277,354,329,0 481,270,512,363,0 502,265,556,448,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/8298c878200eeea6.jpg 762,89,978,621,0 237,193,296,277,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/ba1a001ce1926237.jpg 27,122,332,682,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/26e3407e44f9963c.jpg 169,108,447,723,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/6856891c5c79ec77.jpg 351,15,646,621,0 536,131,945,681,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/5ab57f212ed2565e.jpg 426,0,867,668,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/6d8bdf06bec56286.jpg 107,0,645,998,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/4c722e7f5a2d563d.jpg 72,261,196,550,0 167,253,794,550,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/f1f55363afc15208.jpg 106,0,612,682,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/e136411ec203b462.jpg 0,0,897,575,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/0e3968c61b189040.jpg 55,344,209,505,0 160,350,193,385,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/331eb1e8f9aaa531.jpg 8,365,99,568,0 55,400,177,645,0 61,373,76,395,0 82,372,102,400,0 99,366,113,400,0 102,362,144,422,0 102,385,180,599,0 127,511,280,682,0 140,368,175,423,0 172,359,181,385,0 179,354,192,389,0 193,345,214,381,0 193,357,237,507,0 244,346,291,514,0 315,341,333,361,0 352,345,369,375,0 358,338,399,475,0 366,475,444,682,0 400,349,427,469,0 404,335,413,349,0 421,330,432,361,0 447,432,534,682,0 460,353,475,385,0 461,333,470,346,0 467,334,475,345,0 475,356,486,375,0 478,330,488,342,0 478,354,509,443,0 490,334,499,346,0 503,340,532,445,0 513,322,522,334,0 522,319,532,340,0 529,340,559,441,0 532,448,607,682,0 533,323,545,341,0 553,343,575,379,0 564,330,572,338,0 588,341,607,404,0 605,335,632,406,0 607,320,614,329,0 609,410,660,592,0 615,321,625,333,0 630,331,643,368,0 643,404,689,563,0 648,334,666,370,0 668,316,694,375,0 675,402,740,584,0 676,382,700,523,0 696,354,719,394,0 700,386,742,547,0 714,343,733,365,0 719,325,731,345,0 731,385,756,522,0 737,363,764,404,0 770,369,810,478,0 775,326,783,333,0 782,335,803,362,0 791,325,803,336,0 820,337,828,348,0 821,354,841,385,0 824,363,854,474,0 836,340,851,354,0 851,354,867,383,0 870,263,993,648,0 874,330,883,343,0 887,212,1023,682,0 911,304,953,369,0 927,332,1023,575,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/3df039cedd16afd7.jpg 12,221,166,617,0 152,317,183,419,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/53980d837e2abaf9.jpg 327,372,679,902,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/efc03aba6a4eacb2.jpg 11,171,761,682,0 39,211,137,459,0 121,231,187,403,0 127,305,214,402,0 222,292,309,443,0 407,214,474,396,0 455,219,509,387,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/4b93632604eca286.jpg 69,76,636,1001,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/d0331e7aafb2e234.jpg 0,0,428,738,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/a2c5854d54473846.jpg 171,323,589,872,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/57d39eea630c198d.jpg 133,162,759,759,0 884,340,1023,767,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/8bcc507df43080de.jpg 251,536,378,767,0 469,550,567,767,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/ab6b85adddde0a45.jpg 178,0,619,1004,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/66f4353d945114dd.jpg 125,33,648,994,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/405981e26148094b.jpg 40,221,669,968,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/dfb967617f0852bb.jpg 288,624,538,1006,0 440,600,694,1022,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/302d91933996a207.jpg 365,415,481,748,0 7,409,135,588,0 187,458,316,650,0 254,326,316,450,0 282,429,372,767,0 353,359,418,482,0 358,351,417,431,0 434,296,501,457,0 503,393,584,767,0 569,302,664,483,0 671,339,755,470,0 673,224,721,273,0 712,196,735,259,0 713,310,767,430,0 737,208,771,300,0 764,323,876,523,0 870,284,938,381,0 888,241,916,307,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/009fb367b43706de.jpg 275,283,373,603,0 370,290,472,587,0 454,315,530,608,0 593,280,692,577,0 661,306,774,610,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/b2b3b50c46677ee1.jpg 0,518,148,682,0 222,21,591,409,0 287,487,760,682,0 444,488,572,682,0 736,513,947,682,0 888,566,1019,682,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/fc8d45bfde17e3fa.jpg 198,161,426,922,0 33,199,224,982,0 383,124,662,965,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/616b9cab286aad0e.jpg 279,40,505,558,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/413a404ab4d06014.jpg 271,139,686,992,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/784434fababecac7.jpg 0,50,681,1023,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/de271ecc291f7063.jpg 8,0,142,331,0 581,47,691,214,0 842,100,1005,285,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/b6a7246ac6216c92.jpg 761,204,1011,675,0 650,248,874,684,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/8a16d2dedbcea4ed.jpg 140,115,987,767,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/3f7bdb465b034b3f.jpg 32,152,457,1024,0 142,305,169,357,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/1f5e460f07a416aa.jpg 217,374,344,663,0 0,290,31,353,0 10,293,95,522,0 93,277,148,512,0 130,268,185,347,0 255,267,320,375,0 323,262,342,296,0 343,255,356,288,0 376,295,589,682,0 426,292,495,398,0 428,261,457,299,0 442,251,495,320,0 516,273,545,308,0 533,260,553,292,0 533,265,613,373,0 591,256,614,311,0 724,265,792,424,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/e11adb457bdaffa4.jpg 81,126,318,548,0 152,108,245,204,0 177,423,642,784,0 326,72,552,619,0 329,60,419,507,0 339,118,358,158,0 532,79,650,307,0 632,86,776,573,0 646,322,973,748,0 740,102,756,136,0 763,102,773,126,0 817,47,989,534,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/b6e4d55461b0c2b8.jpg 0,22,279,714,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/591fb3bc773adfb8.jpg 744,220,847,577,0 74,225,144,370,0 77,227,109,294,0 172,253,222,474,0 543,223,646,393,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/532cc84ff3bd9a50.jpg 87,0,287,602,0 0,0,97,626,0 273,88,397,556,0 449,148,590,493,0 524,178,618,472,0 607,185,640,452,0 728,77,906,588,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/e6e19e4e7a82e1c6.jpg 109,349,338,856,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/4850c0a5869d5c7c.jpg 144,82,1002,681,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/a8d9b813841d1dc1.jpg 67,441,315,704,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/49a7fa0ecc2da4e9.jpg 36,133,256,683,0 250,197,620,683,0 378,0,1023,683,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/4fac4f151a2e933b.jpg 0,547,1023,1023,0 2,125,112,376,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/282f273cdb2765ff.jpg 0,173,239,682,0 189,222,329,596,0 315,204,526,518,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/b52977aa669de38f.jpg 28,184,701,1023,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/2b44feee8a46c08c.jpg 9,247,151,682,0 212,242,341,682,0 318,237,422,577,0 431,237,620,682,0 551,223,655,319,0 836,202,955,681,0 976,266,1019,401,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/dd41e686ab3c9971.jpg 523,29,918,673,0 171,90,581,681,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/b82a1bb891fedb8c.jpg 34,42,451,663,0 451,531,515,635,0 470,533,555,626,0 499,531,603,649,0 593,407,671,583,0 676,526,734,597,0 679,481,704,566,0 726,518,778,633,0 799,515,842,608,0 826,501,916,627,0 993,350,1023,439,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/e1e835a5e8203148.jpg 78,245,306,677,0 144,368,552,766,0 400,98,515,354,0 659,101,970,490,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/012c85cb22c6b3f0.jpg 225,248,341,630,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/18d81cf634a3164c.jpg 73,266,741,1024,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/93513c407f12479b.jpg 592,47,940,771,0 66,53,124,263,0 352,37,451,309,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/969472f0d3041d84.jpg 0,541,767,1023,0 230,719,469,1023,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/c8a23107a4b5c284.jpg 712,189,870,655,0 0,253,44,458,0 136,283,160,323,0 264,220,370,565,0 356,220,465,590,0 590,190,770,658,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/396ad203e1fe9ab2.jpg 262,129,461,452,0 72,369,164,516,0 136,389,420,693,0 550,302,689,440,0 662,301,767,531,0 824,405,1023,693,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/1edf1c97eaf6d595.jpg 628,201,1024,947,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/7acf2bee29ea96ac.jpg 24,155,279,802,0 367,133,589,378,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/4345026a054a26e3.jpg 254,40,776,1024,0 742,315,867,493,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/8bcd092acca86d24.jpg 0,172,888,680,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/2458fee481d54672.jpg 88,215,166,499,0 220,223,271,435,0 265,210,367,566,0 426,193,535,337,0 510,243,568,352,0 535,198,555,226,0 585,197,678,351,0 694,205,724,277,0 735,189,767,221,0 739,192,808,370,0 817,198,909,542,0 826,204,855,255,0 904,198,960,366,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/a5e2a9aa13c591f3.jpg 257,130,598,667,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Man/cf0c84d29155e415.jpg 53,671,528,996,0 486,0,835,781,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/4e12be8dfad96dd9.jpg 521,131,694,567,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/544260b3d28780a7.jpg 75,68,473,641,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/eb47ee249c65f1fe.jpg 3,0,429,676,1 371,0,682,951,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/1e0c3759d8f982f0.jpg 17,725,132,952,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/d680921a71d8f223.jpg 0,144,767,1023,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/8278f4fb6c5007ed.jpg 134,141,247,466,1 246,129,334,485,1 418,77,516,313,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/983dfbbcfdff16ca.jpg 513,212,993,670,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/ce44137d91d65560.jpg 523,48,874,930,1 148,59,594,1023,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/90dfc72095f9915f.jpg 784,202,968,575,1 99,302,135,461,1 202,300,287,513,1 203,270,237,314,1 323,273,374,329,1 379,280,471,531,1 639,289,725,485,1 707,232,753,453,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/27f7a7120842f4b8.jpg 35,72,768,1002,1 186,119,979,1005,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/c0616270b97b84ff.jpg 0,592,84,722,1 0,649,121,1016,1 693,590,767,969,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/635ab731a8d68c27.jpg 383,100,989,676,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/1af66f1fc7537063.jpg 461,88,937,690,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/2c64d7ffb1bed72c.jpg 301,254,483,524,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/6dec9aaaa87ef7a4.jpg 300,177,828,673,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/9af3d1047c517424.jpg 444,206,492,337,1 445,177,464,232,1 495,213,531,336,1 504,172,530,213,1 524,202,563,357,1 872,207,910,244,1 877,215,947,395,1 972,286,1023,416,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/a2b336e494e6bcf6.jpg 341,151,746,681,1 0,227,389,680,1 726,160,1023,680,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/381196d8deb810ed.jpg 207,676,367,1014,1 31,584,183,1022,1 111,662,258,1022,1 314,556,441,1022,1 417,519,604,1022,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/326bc363e187cdc6.jpg 204,343,329,614,1 556,271,642,420,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/09921beee0300a8b.jpg 154,109,761,677,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/6aa6a12f0e911e24.jpg 0,270,41,650,1 411,74,1023,682,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/e57249c62d52086e.jpg 315,280,534,509,1 822,217,1002,399,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/f14b63f48b4ca744.jpg 255,97,620,768,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/f4e563d016c886da.jpg 0,372,246,575,1 0,479,262,975,1 29,305,90,477,1 165,304,244,514,1 447,698,682,1023,1 519,264,559,421,1 551,262,636,449,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/353f353405c71138.jpg 385,244,576,455,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/ed434818a1fd5edf.jpg 536,427,660,751,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/fb1c09d078a99a51.jpg 54,261,483,767,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/1006d3ae361cdeea.jpg 128,122,419,682,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/e97fc5d5a3dca0fc.jpg 164,61,504,565,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/d0cc2b2f28b6353c.jpg 28,79,670,934,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/e15ef30a5b44dab6.jpg 79,20,983,680,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/40e3ac667b78bef1.jpg 45,11,536,1011,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/428de64b144619ef.jpg 464,156,832,762,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/d533c00d65299849.jpg 38,81,589,680,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/2aebabd24a6568b5.jpg 0,468,113,657,1 72,285,303,608,1 229,300,395,594,1 394,328,617,618,1 483,314,632,603,1 605,320,918,634,1 763,322,1022,611,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/07eefbaf03514870.jpg 404,276,465,481,1 63,276,107,366,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/5ab57f212ed2565e.jpg 49,95,506,685,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/2ea7a7c7eb0a2fcd.jpg 365,169,675,752,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/4c722e7f5a2d563d.jpg 61,265,173,566,1 157,262,247,547,1 800,280,889,540,1 880,295,974,548,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/f1f55363afc15208.jpg 603,0,947,682,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/7cdfa0e026481918.jpg 188,243,468,964,1 0,187,145,1004,1 468,224,682,993,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/6def8fa38fa567e8.jpg 208,140,723,713,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/3024583e42dbbf79.jpg 95,333,134,379,1 209,327,248,375,1 410,288,639,682,1 859,338,916,518,1 870,347,956,550,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/e31ca6fe9108689c.jpg 0,91,555,767,1 25,92,92,388,1 328,85,410,181,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/675d92996d6adf11.jpg 46,214,484,1023,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/82043506added650.jpg 383,241,523,401,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/7c0ba93e5f7abdb5.jpg 743,2,1005,766,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/08702666f8ccc51b.jpg 383,32,903,628,1 0,2,444,645,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/8d28c170c623c7ed.jpg 50,78,425,768,1 515,95,1001,767,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/515c60c41089610d.jpg 609,143,842,714,1 397,284,462,427,1 450,206,586,418,1 803,204,968,723,1 804,227,840,303,1 919,227,982,346,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/0bcf70ef2df5cd07.jpg 359,196,792,752,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/57d39eea630c198d.jpg 54,227,278,767,1 277,210,759,753,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/53bc7f64fa310494.jpg 126,426,191,626,1 197,413,284,644,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/66f4353d945114dd.jpg 36,38,590,1024,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/ce2f1a982c81e29b.jpg 15,142,663,987,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/55aea048d1295c18.jpg 104,51,564,929,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/6ed80addbe21e9d8.jpg 488,103,643,596,1 1,115,366,412,1 349,92,502,593,1 646,110,994,430,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/5c798436bf1e7a95.jpg 378,79,684,638,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/354b774cd563728d.jpg 838,315,964,647,1 0,333,186,682,1 303,331,370,502,1 348,341,422,548,1 399,325,461,513,1 451,329,539,526,1 472,329,556,536,1 682,350,808,656,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/a4e24573ace2240c.jpg 31,104,499,1022,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/b1420185b363520d.jpg 148,26,956,682,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/f84d742c437fbc59.jpg 97,3,337,412,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/b6a7246ac6216c92.jpg 51,196,263,670,1 356,324,483,684,1 467,316,589,684,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/13beb1328e16c5c8.jpg 239,166,710,671,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/3cbbd4fa62853d13.jpg 456,238,616,768,1 0,100,223,767,1 95,234,268,764,1 236,164,350,547,1 318,202,375,314,1 426,206,526,630,1 603,186,690,524,1 662,220,726,445,1 715,155,1023,767,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/ae038291979749cc.jpg 8,319,682,1011,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/d334125beeeb8e15.jpg 0,108,441,767,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/038e72b9e2c6f1b4.jpg 16,392,175,768,1 144,372,251,644,1 387,426,518,767,1 520,404,681,767,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/090e166ef00bc47a.jpg 24,58,819,1015,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/7814bf442aebe8d1.jpg 668,144,861,570,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/942c38cb7d761941.jpg 250,84,1023,1023,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/c776708ba5812d78.jpg 280,69,916,683,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/4cdfd30a4a3e284c.jpg 76,95,839,609,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/08075359ef0d4717.jpg 164,292,205,410,1 399,277,701,586,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/0a56d6d17bbc872a.jpg 513,266,648,654,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/d669f2e3d291f9d3.jpg 532,118,822,683,1 122,255,369,682,1 145,173,570,682,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/c292df9cb50cf855.jpg 253,99,289,133,1 284,93,311,135,1 549,226,838,671,1 641,181,772,450,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/4aa047db278aa484.jpg 175,131,583,620,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/01f94071a2c1b6f8.jpg 24,131,523,1022,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/4fac4f151a2e933b.jpg 591,599,911,1015,1 486,559,540,609,1 579,515,650,630,1 751,541,785,604,1 841,518,876,568,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/d038b1d5cd54a32e.jpg 64,431,246,611,1 589,221,991,681,1 660,270,771,376,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/282f273cdb2765ff.jpg 513,293,785,668,1 518,283,634,536,1 685,273,855,682,1 785,128,1023,682,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/d08ca890b36db1a9.jpg 339,56,669,587,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/f9b9b58126353b35.jpg 101,146,494,556,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/2b44feee8a46c08c.jpg 0,309,26,631,1 91,301,237,682,1 270,255,365,682,1 310,246,480,682,1 544,163,758,682,1 569,244,652,682,1 704,267,863,682,1 768,263,871,682,1 936,233,1023,682,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/a063a13ca15a9f9d.jpg 141,422,325,1023,1 278,499,457,1023,1 302,121,334,186,1 336,119,375,184,1 368,132,400,181,1 537,148,576,194,1 592,168,612,219,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/aa64125ca6cfdbfc.jpg 210,248,528,1008,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/99426f18ccf6b556.jpg 410,344,575,762,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/93b8af4db5455d7e.jpg 381,195,799,658,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/8b67aad6f1a180c4.jpg 182,78,917,669,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/95d5b94bee148615.jpg 131,98,449,638,1 0,0,164,365,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/22e36ff54a3b0b04.jpg 31,448,147,725,1 579,485,643,693,1 671,479,797,707,1 782,467,901,698,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/e1e835a5e8203148.jpg 242,254,322,405,1 501,178,658,398,1 616,218,746,397,1 896,96,1022,408,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/479a80a4c971eae6.jpg 0,52,761,1005,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/92c2e07894d78d63.jpg 418,268,540,506,1 338,229,428,545,1 497,292,548,345,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/46d4049eefb0b621.jpg 50,843,100,988,1 437,824,519,1023,1 494,846,529,989,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/93513c407f12479b.jpg 42,50,367,770,1 366,147,620,770,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/7acf2bee29ea96ac.jpg 255,128,395,466,1 402,281,708,798,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/4345026a054a26e3.jpg 78,290,238,797,1 150,242,370,1023,1 792,368,961,568,1 822,295,1023,1023,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/train/Woman/2458fee481d54672.jpg 344,218,452,541,1 156,235,221,446,1 536,205,573,284,1 652,221,700,364,1 712,221,751,367,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Man/c9e86162f86f1d20.jpg 215,161,565,949,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Man/182c2d9a97a46c19.jpg 238,323,485,654,0 401,294,846,728,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Man/d3ffd0efe54ddaff.jpg 455,105,1022,765,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Man/70b71a7ae0e52b19.jpg 226,199,450,569,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Man/0a45605d34b7471d.jpg 1,132,96,683,0 215,146,569,683,0 549,223,667,601,0 646,151,961,681,0 894,218,961,362,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Man/be171ae26c964084.jpg 402,129,844,593,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Man/0ac281ffb2e0017f.jpg 0,424,646,768,0 465,398,589,640,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Man/5fc131efa7988d86.jpg 245,86,584,505,0 474,46,651,393,0 553,3,829,523,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Man/bc383971045dc428.jpg 174,24,620,1024,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Man/649c81940026b967.jpg 124,173,481,706,0\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Woman/7ffa939fdb0dca22.jpg 310,127,616,999,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Woman/9139fd94eaace3f0.jpg 0,0,716,683,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Woman/c4abccfd4fcfe3bb.jpg 3,245,259,1022,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Woman/e83bb3f05e8e886e.jpg 1,2,681,1024,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Woman/507432cee49368d6.jpg 73,62,361,991,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Woman/ea77a5067980a833.jpg 190,119,683,1024,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Woman/d822c365586cbc3b.jpg 54,98,741,679,1 809,1,1024,683,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Woman/d3ffd0efe54ddaff.jpg 0,201,222,768,1 0,0,578,768,1 707,129,805,289,1 725,190,910,421,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Woman/eb8cceca1be6203b.jpg 121,162,447,944,1\n",
            "/content/Object_Detection_YOLOv3/data/Dataset/test/Woman/96fc17c3fdb33449.jpg 102,32,599,1023,1\n",
            "Dataset_names: ['Man', 'Woman']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PKzznXz7Uul",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "068d6035-afaa-4392-99e9-77159cbbed6e"
      },
      "source": [
        "!wget -P model_data https://pjreddie.com/media/files/yolov3.weights\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-13 06:39:34--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘model_data/yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  1.02MB/s    in 4m 58s  \n",
            "\n",
            "2020-09-13 06:44:32 (814 KB/s) - ‘model_data/yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t03jGfRz7d-f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7979cba6-bf3b-47b6-ede4-ab468c638883"
      },
      "source": [
        "cd /content/Object_Detection_YOLOv3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Object_Detection_YOLOv3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oovdfeOT8F_T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ebd44ca6-9f96-401c-d4f7-b6e117cd0ff3"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "config\t     download_dataset.py    modules\t     requirements.txt\n",
            "config_data  evaluate_mAP.py\t    OIDv4_ToolKit    train.py\n",
            "data\t     Generate_xml_files.py  Prepare_data.py  yolov3.jpg\n",
            "detect.py    model_data\t\t    README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjjAVQ6U8T6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir logs\n",
        "!mkdir weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDgSsNCW8boe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d6c886c-0bbe-4fed-c5fc-f6508b96e71c"
      },
      "source": [
        "!python /content/Object_Detection_YOLOv3/train.py\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-13 08:27:18.220418: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-13 08:27:19.702138: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-09-13 08:27:19.707504: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-09-13 08:27:19.707549: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 2d3cc28bb7c4\n",
            "2020-09-13 08:27:19.707565: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 2d3cc28bb7c4\n",
            "2020-09-13 08:27:19.707660: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 418.67.0\n",
            "2020-09-13 08:27:19.707695: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.67.0\n",
            "2020-09-13 08:27:19.707722: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 418.67.0\n",
            "2020-09-13 08:27:19.719930: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-09-13 08:27:19.720120: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x140cbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-09-13 08:27:19.720150: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "skipping conv2d_74\n",
            "skipping conv2d_66\n",
            "skipping conv2d_58\n",
            "epoch: 0 step:    2/25, lr:0.000000, giou_loss:   4.08, conf_loss:1612.23, prob_loss:   5.30, total_loss:1621.61\n",
            "epoch: 0 step:    3/25, lr:0.000001, giou_loss:   3.68, conf_loss:1128.76, prob_loss:   5.77, total_loss:1138.22\n",
            "epoch: 0 step:    4/25, lr:0.000001, giou_loss:   5.99, conf_loss:1131.84, prob_loss:   7.97, total_loss:1145.79\n",
            "epoch: 0 step:    5/25, lr:0.000001, giou_loss:   7.99, conf_loss:1129.83, prob_loss:  11.28, total_loss:1149.11\n",
            "epoch: 0 step:    6/25, lr:0.000001, giou_loss:   6.39, conf_loss:1131.47, prob_loss:   8.52, total_loss:1146.38\n",
            "epoch: 0 step:    7/25, lr:0.000001, giou_loss:   8.45, conf_loss:1129.61, prob_loss:  11.93, total_loss:1150.00\n",
            "epoch: 0 step:    8/25, lr:0.000002, giou_loss:   8.55, conf_loss:1129.63, prob_loss:  11.36, total_loss:1149.54\n",
            "epoch: 0 step:    9/25, lr:0.000002, giou_loss:  11.14, conf_loss:1126.83, prob_loss:  13.58, total_loss:1151.55\n",
            "epoch: 0 step:   10/25, lr:0.000002, giou_loss:  23.42, conf_loss:1123.02, prob_loss:  27.55, total_loss:1173.99\n",
            "epoch: 0 step:   11/25, lr:0.000002, giou_loss:   8.86, conf_loss:1126.79, prob_loss:  10.97, total_loss:1146.63\n",
            "epoch: 0 step:   12/25, lr:0.000002, giou_loss:   4.32, conf_loss:1122.96, prob_loss:   5.66, total_loss:1132.95\n",
            "epoch: 0 step:   13/25, lr:0.000003, giou_loss:  13.47, conf_loss:1118.78, prob_loss:  16.79, total_loss:1149.03\n",
            "epoch: 0 step:   14/25, lr:0.000003, giou_loss:   6.71, conf_loss:1117.81, prob_loss:   8.52, total_loss:1133.05\n",
            "epoch: 0 step:   15/25, lr:0.000003, giou_loss:   3.07, conf_loss:1111.38, prob_loss:   4.66, total_loss:1119.11\n",
            "epoch: 0 step:   16/25, lr:0.000003, giou_loss:   6.47, conf_loss:1108.52, prob_loss:   9.77, total_loss:1124.76\n",
            "epoch: 0 step:   17/25, lr:0.000003, giou_loss:  17.40, conf_loss:1105.66, prob_loss:  21.39, total_loss:1144.45\n",
            "epoch: 0 step:   18/25, lr:0.000004, giou_loss:   6.96, conf_loss:1101.02, prob_loss:   9.26, total_loss:1117.24\n",
            "epoch: 0 step:   19/25, lr:0.000004, giou_loss:   4.49, conf_loss:1098.94, prob_loss:   6.31, total_loss:1109.74\n",
            "epoch: 0 step:   20/25, lr:0.000004, giou_loss:   5.11, conf_loss:1096.09, prob_loss:   6.26, total_loss:1107.46\n",
            "epoch: 0 step:   21/25, lr:0.000004, giou_loss:  11.89, conf_loss:1089.41, prob_loss:  16.65, total_loss:1117.95\n",
            "epoch: 0 step:   22/25, lr:0.000004, giou_loss:   4.09, conf_loss:1088.19, prob_loss:   5.56, total_loss:1097.85\n",
            "epoch: 0 step:   23/25, lr:0.000005, giou_loss:   8.01, conf_loss:1082.98, prob_loss:   9.28, total_loss:1100.27\n",
            "epoch: 0 step:   24/25, lr:0.000005, giou_loss:   6.97, conf_loss:1077.15, prob_loss:  10.55, total_loss:1094.67\n",
            "epoch: 0 step:    0/25, lr:0.000005, giou_loss:   3.66, conf_loss:1074.02, prob_loss:   5.60, total_loss:1083.28\n",
            "epoch: 0 step:    1/25, lr:0.000005, giou_loss:   3.98, conf_loss:1068.09, prob_loss:   5.37, total_loss:1077.44\n",
            "\n",
            "\n",
            "giou_val_loss:   3.23, conf_val_loss:1219.85, prob_val_loss:   5.12, total_val_loss:1228.19\n",
            "\n",
            "\n",
            "epoch: 1 step:    2/25, lr:0.000005, giou_loss:   8.05, conf_loss:1065.28, prob_loss:  11.83, total_loss:1085.16\n",
            "epoch: 1 step:    3/25, lr:0.000006, giou_loss:   3.48, conf_loss:1059.21, prob_loss:   5.72, total_loss:1068.41\n",
            "epoch: 1 step:    4/25, lr:0.000006, giou_loss:  11.02, conf_loss:1057.03, prob_loss:  13.36, total_loss:1081.41\n",
            "epoch: 1 step:    5/25, lr:0.000006, giou_loss:  18.55, conf_loss:1055.35, prob_loss:  22.71, total_loss:1096.60\n",
            "epoch: 1 step:    6/25, lr:0.000006, giou_loss:  20.33, conf_loss:1050.80, prob_loss:  23.90, total_loss:1095.03\n",
            "epoch: 1 step:    7/25, lr:0.000006, giou_loss:   7.45, conf_loss:1042.31, prob_loss:  10.65, total_loss:1060.41\n",
            "epoch: 1 step:    8/25, lr:0.000007, giou_loss:   7.19, conf_loss:1037.99, prob_loss:  10.17, total_loss:1055.35\n",
            "epoch: 1 step:    9/25, lr:0.000007, giou_loss:   9.77, conf_loss:1036.95, prob_loss:  13.28, total_loss:1060.01\n",
            "epoch: 1 step:   10/25, lr:0.000007, giou_loss:   5.50, conf_loss:1031.92, prob_loss:   7.44, total_loss:1044.86\n",
            "epoch: 1 step:   11/25, lr:0.000007, giou_loss:   5.98, conf_loss:1028.64, prob_loss:   8.14, total_loss:1042.76\n",
            "epoch: 1 step:   12/25, lr:0.000007, giou_loss:   5.71, conf_loss:1025.30, prob_loss:   7.75, total_loss:1038.77\n",
            "epoch: 1 step:   13/25, lr:0.000008, giou_loss:   5.39, conf_loss:1018.48, prob_loss:   7.18, total_loss:1031.05\n",
            "epoch: 1 step:   14/25, lr:0.000008, giou_loss:   4.91, conf_loss:1017.43, prob_loss:   6.58, total_loss:1028.92\n",
            "epoch: 1 step:   15/25, lr:0.000008, giou_loss:   5.76, conf_loss:1010.27, prob_loss:   7.88, total_loss:1023.92\n",
            "epoch: 1 step:   16/25, lr:0.000008, giou_loss:  10.33, conf_loss:1004.88, prob_loss:  13.76, total_loss:1028.97\n",
            "epoch: 1 step:   17/25, lr:0.000008, giou_loss:   5.16, conf_loss:1001.71, prob_loss:   7.93, total_loss:1014.81\n",
            "epoch: 1 step:   18/25, lr:0.000009, giou_loss:   3.83, conf_loss: 999.11, prob_loss:   5.53, total_loss:1008.47\n",
            "epoch: 1 step:   19/25, lr:0.000009, giou_loss:   4.57, conf_loss: 993.91, prob_loss:   6.91, total_loss:1005.39\n",
            "epoch: 1 step:   20/25, lr:0.000009, giou_loss:  10.73, conf_loss: 989.83, prob_loss:  13.21, total_loss:1013.77\n",
            "epoch: 1 step:   21/25, lr:0.000009, giou_loss:   2.44, conf_loss: 983.03, prob_loss:   4.07, total_loss: 989.54\n",
            "epoch: 1 step:   22/25, lr:0.000009, giou_loss:   8.55, conf_loss: 982.69, prob_loss:  12.49, total_loss:1003.73\n",
            "epoch: 1 step:   23/25, lr:0.000010, giou_loss:   5.26, conf_loss: 974.47, prob_loss:   7.41, total_loss: 987.14\n",
            "epoch: 1 step:   24/25, lr:0.000010, giou_loss:   6.08, conf_loss: 968.29, prob_loss:   8.41, total_loss: 982.78\n",
            "epoch: 1 step:    0/25, lr:0.000010, giou_loss:   6.84, conf_loss: 967.90, prob_loss:   8.84, total_loss: 983.57\n",
            "epoch: 1 step:    1/25, lr:0.000010, giou_loss:   6.78, conf_loss: 960.93, prob_loss:   8.60, total_loss: 976.31\n",
            "\n",
            "\n",
            "giou_val_loss:   3.00, conf_val_loss:1055.77, prob_val_loss:   5.04, total_val_loss:1063.81\n",
            "\n",
            "\n",
            "epoch: 2 step:    2/25, lr:0.000010, giou_loss:   4.23, conf_loss: 953.38, prob_loss:   5.77, total_loss: 963.38\n",
            "epoch: 2 step:    3/25, lr:0.000010, giou_loss:   3.29, conf_loss: 950.77, prob_loss:   5.37, total_loss: 959.43\n",
            "epoch: 2 step:    4/25, lr:0.000010, giou_loss:   2.92, conf_loss: 945.04, prob_loss:   4.44, total_loss: 952.40\n",
            "epoch: 2 step:    5/25, lr:0.000010, giou_loss:   8.12, conf_loss: 940.72, prob_loss:  10.78, total_loss: 959.62\n",
            "epoch: 2 step:    6/25, lr:0.000010, giou_loss:   2.64, conf_loss: 932.43, prob_loss:   5.01, total_loss: 940.08\n",
            "epoch: 2 step:    7/25, lr:0.000010, giou_loss:  10.51, conf_loss: 933.64, prob_loss:  14.29, total_loss: 958.44\n",
            "epoch: 2 step:    8/25, lr:0.000010, giou_loss:  24.34, conf_loss: 930.52, prob_loss:  29.08, total_loss: 983.94\n",
            "epoch: 2 step:    9/25, lr:0.000010, giou_loss:   5.68, conf_loss: 925.46, prob_loss:   8.23, total_loss: 939.36\n",
            "epoch: 2 step:   10/25, lr:0.000010, giou_loss:   4.77, conf_loss: 917.50, prob_loss:   8.15, total_loss: 930.42\n",
            "epoch: 2 step:   11/25, lr:0.000010, giou_loss:   2.38, conf_loss: 913.04, prob_loss:   4.07, total_loss: 919.50\n",
            "epoch: 2 step:   12/25, lr:0.000010, giou_loss:   4.88, conf_loss: 909.24, prob_loss:   7.84, total_loss: 921.96\n",
            "epoch: 2 step:   13/25, lr:0.000010, giou_loss:   3.26, conf_loss: 903.97, prob_loss:   5.16, total_loss: 912.38\n",
            "epoch: 2 step:   14/25, lr:0.000010, giou_loss:  10.99, conf_loss: 903.73, prob_loss:  14.86, total_loss: 929.59\n",
            "epoch: 2 step:   15/25, lr:0.000010, giou_loss:   7.68, conf_loss: 900.00, prob_loss:  10.39, total_loss: 918.07\n",
            "epoch: 2 step:   16/25, lr:0.000010, giou_loss:  11.33, conf_loss: 898.74, prob_loss:  16.61, total_loss: 926.67\n",
            "epoch: 2 step:   17/25, lr:0.000010, giou_loss:   5.53, conf_loss: 886.52, prob_loss:   8.66, total_loss: 900.71\n",
            "epoch: 2 step:   18/25, lr:0.000010, giou_loss:   7.35, conf_loss: 884.46, prob_loss:  11.45, total_loss: 903.26\n",
            "epoch: 2 step:   19/25, lr:0.000010, giou_loss:   7.38, conf_loss: 883.31, prob_loss:  10.00, total_loss: 900.69\n",
            "epoch: 2 step:   20/25, lr:0.000010, giou_loss:  10.78, conf_loss: 881.54, prob_loss:  13.52, total_loss: 905.84\n",
            "epoch: 2 step:   21/25, lr:0.000010, giou_loss:  13.46, conf_loss: 873.61, prob_loss:  18.57, total_loss: 905.64\n",
            "epoch: 2 step:   22/25, lr:0.000010, giou_loss:   6.89, conf_loss: 869.89, prob_loss:   9.83, total_loss: 886.60\n",
            "epoch: 2 step:   23/25, lr:0.000010, giou_loss:   3.70, conf_loss: 863.67, prob_loss:   5.78, total_loss: 873.15\n",
            "epoch: 2 step:   24/25, lr:0.000010, giou_loss:  10.80, conf_loss: 861.66, prob_loss:  14.60, total_loss: 887.06\n",
            "epoch: 2 step:    0/25, lr:0.000010, giou_loss:   5.30, conf_loss: 858.08, prob_loss:   8.03, total_loss: 871.41\n",
            "epoch: 2 step:    1/25, lr:0.000010, giou_loss:   3.78, conf_loss: 852.31, prob_loss:   6.35, total_loss: 862.43\n",
            "\n",
            "\n",
            "giou_val_loss:   2.74, conf_val_loss: 909.33, prob_val_loss:   4.95, total_val_loss: 917.02\n",
            "\n",
            "\n",
            "epoch: 3 step:    2/25, lr:0.000010, giou_loss:   5.59, conf_loss: 848.79, prob_loss:   8.43, total_loss: 862.80\n",
            "epoch: 3 step:    3/25, lr:0.000010, giou_loss:   5.87, conf_loss: 841.88, prob_loss:   8.54, total_loss: 856.29\n",
            "epoch: 3 step:    4/25, lr:0.000010, giou_loss:   2.69, conf_loss: 839.08, prob_loss:   5.46, total_loss: 847.23\n",
            "epoch: 3 step:    5/25, lr:0.000010, giou_loss:   6.50, conf_loss: 841.68, prob_loss:   9.97, total_loss: 858.14\n",
            "epoch: 3 step:    6/25, lr:0.000010, giou_loss:   5.71, conf_loss: 837.99, prob_loss:   8.99, total_loss: 852.68\n",
            "epoch: 3 step:    7/25, lr:0.000010, giou_loss:   7.51, conf_loss: 831.59, prob_loss:  10.51, total_loss: 849.60\n",
            "epoch: 3 step:    8/25, lr:0.000010, giou_loss:  11.74, conf_loss: 828.45, prob_loss:  15.91, total_loss: 856.09\n",
            "epoch: 3 step:    9/25, lr:0.000010, giou_loss:   3.84, conf_loss: 827.42, prob_loss:   7.02, total_loss: 838.27\n",
            "epoch: 3 step:   10/25, lr:0.000010, giou_loss:   8.35, conf_loss: 819.49, prob_loss:  11.97, total_loss: 839.81\n",
            "epoch: 3 step:   11/25, lr:0.000010, giou_loss:   8.32, conf_loss: 817.85, prob_loss:  11.51, total_loss: 837.68\n",
            "epoch: 3 step:   12/25, lr:0.000010, giou_loss:   8.02, conf_loss: 815.46, prob_loss:  10.92, total_loss: 834.40\n",
            "epoch: 3 step:   13/25, lr:0.000010, giou_loss:   3.83, conf_loss: 807.63, prob_loss:   6.73, total_loss: 818.18\n",
            "epoch: 3 step:   14/25, lr:0.000010, giou_loss:  11.28, conf_loss: 809.84, prob_loss:  15.15, total_loss: 836.27\n",
            "epoch: 3 step:   15/25, lr:0.000010, giou_loss:  19.34, conf_loss: 802.74, prob_loss:  24.37, total_loss: 846.45\n",
            "epoch: 3 step:   16/25, lr:0.000010, giou_loss:   2.53, conf_loss: 802.65, prob_loss:   4.92, total_loss: 810.10\n",
            "epoch: 3 step:   17/25, lr:0.000010, giou_loss:   3.56, conf_loss: 795.00, prob_loss:   5.66, total_loss: 804.22\n",
            "epoch: 3 step:   18/25, lr:0.000010, giou_loss:   5.95, conf_loss: 794.41, prob_loss:   9.30, total_loss: 809.65\n",
            "epoch: 3 step:   19/25, lr:0.000010, giou_loss:   5.05, conf_loss: 791.10, prob_loss:   7.79, total_loss: 803.94\n",
            "epoch: 3 step:   20/25, lr:0.000010, giou_loss:   4.85, conf_loss: 786.15, prob_loss:   7.19, total_loss: 798.19\n",
            "epoch: 3 step:   21/25, lr:0.000010, giou_loss:   5.27, conf_loss: 778.45, prob_loss:   8.88, total_loss: 792.61\n",
            "epoch: 3 step:   22/25, lr:0.000010, giou_loss:  12.76, conf_loss: 784.35, prob_loss:  18.36, total_loss: 815.47\n",
            "epoch: 3 step:   23/25, lr:0.000010, giou_loss:   8.21, conf_loss: 773.17, prob_loss:  11.72, total_loss: 793.10\n",
            "epoch: 3 step:   24/25, lr:0.000010, giou_loss:   5.09, conf_loss: 770.92, prob_loss:   9.34, total_loss: 785.36\n",
            "epoch: 3 step:    0/25, lr:0.000010, giou_loss:   7.71, conf_loss: 767.76, prob_loss:  11.51, total_loss: 786.98\n",
            "epoch: 3 step:    1/25, lr:0.000010, giou_loss:   1.53, conf_loss: 764.23, prob_loss:   3.31, total_loss: 769.06\n",
            "\n",
            "\n",
            "giou_val_loss:   2.57, conf_val_loss: 802.11, prob_val_loss:   4.90, total_val_loss: 809.58\n",
            "\n",
            "\n",
            "epoch: 4 step:    2/25, lr:0.000010, giou_loss:   4.32, conf_loss: 758.77, prob_loss:   6.39, total_loss: 769.48\n",
            "epoch: 4 step:    3/25, lr:0.000010, giou_loss:   9.44, conf_loss: 759.44, prob_loss:  14.65, total_loss: 783.53\n",
            "epoch: 4 step:    4/25, lr:0.000010, giou_loss:   6.20, conf_loss: 753.09, prob_loss:  10.04, total_loss: 769.33\n",
            "epoch: 4 step:    5/25, lr:0.000010, giou_loss:   4.36, conf_loss: 750.53, prob_loss:   7.30, total_loss: 762.19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4ctoq4w-tAL",
        "colab_type": "text"
      },
      "source": [
        "**Detect model**\n",
        "\n",
        "As you can see, it does not take so much time to train. it’s actually pretty fast. Let’s test the trained model!\n",
        "Before detecting, you have to edit this file and determine which image or video you insert as an input, as well as the image or video output directory.\n",
        "In addition, you have to adjust the last row in the script to your preferences: image, video or real-time.\n",
        "For an image:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aHnYK2I-ozn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "638198de-fdf0-4305-f7c6-ea6ff0094e55"
      },
      "source": [
        "#image\n",
        "!python /content/Object_Detection_YOLOv3/detect.py\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-13 08:26:16.874013: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-13 08:26:18.324512: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-09-13 08:26:18.365989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-13 08:26:18.366628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-09-13 08:26:18.366689: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-13 08:26:18.368572: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-09-13 08:26:18.370455: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-09-13 08:26:18.370867: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-09-13 08:26:18.372650: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-09-13 08:26:18.373799: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-09-13 08:26:18.377808: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-13 08:26:18.377940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-13 08:26:18.378608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-13 08:26:18.379152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-09-13 08:26:18.385772: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-09-13 08:26:18.385992: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1ebcbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-09-13 08:26:18.386034: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-09-13 08:26:18.498860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-13 08:26:18.499588: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1ebcd80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-09-13 08:26:18.499629: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-09-13 08:26:18.499854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-13 08:26:18.500427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-09-13 08:26:18.500494: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-13 08:26:18.500542: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-09-13 08:26:18.500571: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-09-13 08:26:18.500596: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-09-13 08:26:18.500618: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-09-13 08:26:18.500643: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-09-13 08:26:18.500668: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-13 08:26:18.500752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-13 08:26:18.501347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-13 08:26:18.501881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-09-13 08:26:18.501955: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-13 08:26:19.159798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-13 08:26:19.159867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-09-13 08:26:19.159881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-09-13 08:26:19.160105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-13 08:26:19.160894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-13 08:26:19.161590: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-09-13 08:26:19.161662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2020-09-13 08:26:27.017348: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-13 08:26:28.735619: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho5ZLi8T_ONk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#video\n",
        "!python /content/Object_Detection_YOLOv3/detect.py"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}